---
title: '意思決定のための、ゼロからはじめる統計とデータ分析のお話'
author: '石井 遼介 / @ryouen'
date: "March 8, 2019"
output:
  bookdown::gitbook: default
  html_document:  
    latex_engine: xelatex
    df_print: paged
    toc: true
    toc_float: true
    toc_depth: '2'
  pdf_document:
#    latex_engine: xelatex
    df_print: kable
    number_sections: yes
    toc: no
    toc_depth: 
output_file: "index.html"
fontsize: 11pt
#bibliography: mybibfile.bib
mainfont: Meiryo
monofont: Meiryo
---


```{r include=FALSE}
#install.packages("bookdown")
#install.packages("rmarkdown")
#install.packages("knitr")
#install.packages("devtools", dependencies = TRUE)
#install.packages("reticulate") #このパッケージを使うと、'''{python} チャンクでPythonを実行する時、チャンクをまたいだ処理も可能になる
#devtools::install_github("rstudio/rmarkdown")
library(bookdown)
library(rmarkdown)
library(knitr)
library(reticulate)
```

```{r include=FALSE}
#install.packages("dplyr")
library(dplyr)
library(ggplot2)
```


#index{-}
このページでは「意思決定のためのデータ分析」入門編として、機械学習をやってみたい、AI入門したい、あるいは、統計をゼロから学びたい、という方のために、統計やデータ分析の基礎を、**わかりやすく、けれど、本質を損なわないように**お伝えしていきます。

データ分析と統計の基礎を学ぶことで、

 - 未来を予測し、自分や相手、顧客の行動を制御する
 - いま、何が起きているのか。起きていることから、真実に迫る構造を抽出する

ことが上達します。

筆者はRとPythonを使いますが、[こちらのGithubのリポジトリに利用するファイルをすべて置いて](https://github.com/ryouen/ryouen.github.io/tree/master/stat)おきます。環境構築には、Rは[R 3.5.2](https://cran.r-project.org/src/base/R-3) と、[RStudio](https://www.rstudio.com/products/rstudio/download/)、Pythonは[Anaconda](https://www.anaconda.com/distribution/)のJupyter Notebookを使っています。

```{r echo=FALSE}

scatter <- ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width)) 
scatter + geom_point(aes(color=Species, shape=Species)) +
  xlab("Sepal Length") +  ylab("Sepal Width") +
  ggtitle("Sepal Length-Width")
```


##本書の特徴{-}

RやPythonをはじめ、SPSSなど、データ分析ツールを使えば、
「とりあえずt検定をしてみました。p値が5%以下なので、統計的有意です！」ということは、
少し頑張れば、誰でもできるようになってきました。

本書では、**ツールの使い方ではなく、やっていることの意味がわかる**ことを重視します。
「数学がわかったほうが、理解が早くて深まる」ことは確かですが、
**「数式を飛ばし読み」しながらでも理解できる**ように工夫をしました。

また、統計学に限らず、ほとんどの学問は、英語で最新情報が交換されています。
そちらへの接続が簡単となるよう、折に触れて英単語を付記しているのも、本書の特徴です。


###対象読者{-}
 - 得られるもの
    + 単なる理論でも、単なるツールの使いかたでもなく、ある分析ツールを使うとき「自分が何をやっているか、わかる」ようになる
    + 具体的にデータ分析ができるようになる、ステップを理解できる

 - 対象読者レベル① (頑張ればついていける)
    + 1次関数 $y = ax + b$ は、なんとなくわかる
    + 「変数」という言葉が、上の式のいろいろ変わるところ、つまり$x,y$のことだと、なんとなく言われれば思い出せる
    + Excelで散布図(scatter-plot)や、関数を使ってみたことがある

 - 対象読者レベル②（もっとも実りが多そう）
    + 数学はそれほど苦手ではないが、統計の数学だけは難しいと感じる(そうです、統計の数学には罠があります)
    + なんとなく、anova()とかt.test()とかやってきたければ、イマイチ、自分が何をしているか分からない
    + 「p値が小さければ、小さいほど、効果あったと言える」という**勘違いをしている**人
    + データ分析はある程度やったことがあるが、もっと意思決定にデータを活かしたい人。
    +これから統計・データサイエンスに入門するヒト。機械学習とかAIとかの入り口にたった人
    
 - 対象読者レベル③（未来のために、本当に読んでほしい）
    + 社会科学の教授クラスで、学生時代に学んだ統計で統計の学習が止まっている人
    + カテゴリ変数(0, 1)以外と、Numerical Variablesを掛け算してfitingしてる人


などが、対象となる読者のイメージです。


数式などが**まったく**分からない、なんなら怖い。という方は、
[こちらの物理の例を使って、数学をマスターできるスライド資料](https://www.slideshare.net/ryouen/mathphysicsmastersv1)をご参考ください。
上記の資料がサクサクわかる状態であれば、本書の数学はそれほど苦労しないはずです（意味が分からなくても、読み飛ばせるはずです）

###数式はこわくない{-}
この統計分析では「数式」を使います。
数式について、苦手意識がある方は、この章をこのまま読み進めてから、本題に入ってください。
数式に苦手意識などないよ、という方は、早速第１章から入っていきましょう。

###数式は「ラク」をするためにある{-}
統計を学ぶ上で、「数式」は避けられません。
数式というと、苦手、難しそう、なんなら「得体が知れなくて怖い！」という方もいらっしゃるかもしれません。
しかし、数式は、実は「ラクをするために」あるのです、と言ったら、驚かれるでしょうか？

例えば、もしあなたが数式が苦手なら、

\[
  \sum_{x=1}^{5} x
\]


みたいなのは、できれば見たくないですよね。


ではぎゃくに、こういうのを見るとどうでしょう？
\[
いち　たす　に　たす　さん　たす　よん　たす　ご
\]

さすがに、

\[
1+2+3+4+5
\]
と書いてよね、まどろっこしいなあ。などと、思われるのではないでしょうか。


**実は、本質的には、すべての数学の記号は、これと同じ。長い言葉を省略しているに過ぎません。**

他の例でいくと、小学生や中学生の頃、速さと時間と距離の関係を、
は(速さ)、じ(時間)、き(距離)、はじき。なんて略したりしましたよね。
物理学で、\[vt=x\]なんて書くと小難しく見えますが、
これは、\[速さ\times 時間=距離。　略して：　はじ=き\]と言っているのと、本質的には何も変わりません。


###難しいのではなく、知らない{-}

いまの\[はじ=き\]の例で重要なのは、
あなたがいかに頭が良くても（そうですね、かの大天才、アインシュタインが来日して、この\[はじ=き\] の一行だけを見たと考えてください）。
そのような天才であっても、**速さを省略して「は」と書きましたよ、ということを知らなければ、絶対に意味はわからない**。
ということです。


だから、数式を見たら、一度それを「日本語へ翻訳」してみてください。
たとえば、先程みた

\[
  \sum_{x=1}^{5} x
\]
この数式は、
\[
1から5まで、順番に足していって。つまり、1+2+3+4+5をして！
\]

という「日本語へ翻訳」できます。

**日本語へ翻訳できないこ時、それは、数式が難しいのではなく、あなたがその数式を知らないだけ**なのです。
知識がない時、必要なのは落ち込むことではなく、知ることです。調べることです。
「何を省略しているのか、一度日本語にしてみよう。その上で、わかるかわからないか、確認しよう」
というのが、知らない数式を見た時、より学べる態度です。


もっと言えば、**大事なことは「数式に慣れる」こと**です。
わたしたちは、本当にはよく分からなくても、見慣れているものを「わかる」と思う生き物です。

例えば、いつも使っている携帯電話は、統計で学ぶひとつひとつの数式に比べると、
高度なテクノロジーの塊で、とても難しいはずです。

けれど「なぜ、そのボタンを押すと、遠く離れたヒトと話ができるという、魔術的なことが起きるのか？？う～～ん、まったくわからん。俺は頭が悪いのだろうか。。」と落ち込むことなどなく、自然に使いこなしているはずです。

数式は、むしろ「語学」だと思って、むかし英語の単語帳を何度も見て覚えたように、
そして今では「Pen」という単語を見ると、「なんだっけ、えーと、確か、ペンだな」などと思うことなく、
「Pen」が指し示すものを、１秒のタイムラグもなく理解できるように、
統計の数式にも、時間をかけて、何度も見て、慣れていくことが大切です。

ですから、
\[
\sum_{i=1}^{5} x_i= x_1 + x_2 + x_3+ x_4 + x_5
\]
みたいな式を何度も見て、「ただ慣れること」。つまり、右側の式を省略してラクしようとして書いたのが左側。自然なことだよな。となるまで、
何度も見る。なんなら音読する。写経する、というのは、以外とバカにならず、大切です。


そう、新しい英単語を、一度見てすぐに使えるようにならないのと同じように、
新しい数式に、時間をかけて慣れ親しんでいきましょう。


#最強分析ツール、回帰分析(Regression)！

回帰(Regression)とは、**1つの興味がある、予測や理解したいデータ(目的変数/Target)**を、
他のいくつかの、よくわかっているパラメーターで説明することです。

例えば、「売上」という「目的変数」に興味があるとき、もしかすると、「営業マンの数」と「投下する広告宣伝費」という2つの変数を使って、
予測することができるかもしれません。「例えば、マーケティング予算が変わらないなら、あと３人、セールスパーソンを採用すれば、予算が達成できるのではないか」などと言ったことです。


2012年に回帰分析ハンドブック[Handbook of Regression Analysis](https://amzn.to/2Tsa6yd) を書いたニューヨーク大学教授のSimonoff Jeffrey先生は、

> **「回帰は、いまのところ、人類が持てる最高のデータ分析ツールだ」**

> Regression is by far in a way most useful Data Analytic method 
> every data mining method ever invented.

と言いました。

ラノベであれば、

>『邪悪なデータめ！喰らえ ーー最強分析奥義（リガレッション）！！』

などとなる ところでしょうか。


なぜ、そんなにも「最強」と言い切れるのか？
それは、回帰分析だけが、次の３つのことが、**すべて** できるからです。

1. Prediction / forecasting: 観察できていないものの予測/時間的な予測(未来予測)
2. Model building: 変数間の関係性(relationship of variables)を理解するため(これを増やすと、売上が上がる)
3. Testing Hypothesis: 仮説を確認(test)するため

予測だけや、モデルづくりだけができるメソッド/分析ツールは他にもありますが、
**回帰だけが、これら３つを同時に満たす**のです。

それでは、回帰分析の中でも一番シンプルな回帰、「線形回帰(Linear Regression)」を
次の章からはじめましょう。


#線形回帰分析 - Linear Regression 1.単回帰分析


>All model is wrong but some are useful. 
>
> Model is a representation of truth. It is not actually the truth.
>
>We are assuming reasonable representation.

>すべてのモデルは「真実」ではないが、役に立つ。
>
>モデルとは、真実を「表象」するものであり「真実そのもの」ではない
>
>我々は、合理的な表象を想定するのだ。


「単回帰」分析、あるいは、Simple Regressionをするとき、たとえば身長と体重、人口密度と犯罪率、父親の身長と息子の身長、マーケティング予算と売上など、
**２つ**の要素 - 「変数」と呼び、それぞれ$x, y$で表現することが多いのですが、その関係に興味があります。

$y$ を興味のある変数、より理解したい変数とし、つまり、target variable, (ターゲット・目的変数)と呼びます。

この${}y{} を、x$を使って予測したり分析したり説明したりするので、$x$を説明変数(predictor, predicting variableと呼びます。


例えば、あなたがマーケティングの責任者であれば、マーケティング予算が、説明変数$x$、それによって予測する売上が、目的変数$y$ということになります。これは、マーケティング予算は適切な権限があれば、決めることができる(操作可能)ですが、売上は結果に過ぎないため、売上を直接コントロールすることはできないからです。


また、もし「どこに住もうかな」とあなたが考えているとすると、
人口密度が説明変数 $x$ で、犯罪率が目的変数 $y$ だということになります。
住む場所、つまり人口密度はこれから選ぶことができますが、犯罪率自体はコントロールできないからです。


このように、$x$ によって説明する、$y$ の変化を知ること、しかも、**シンプルに直線で知ることを、「単回帰分析」**といいます。


まず、単回帰分析のツールや関数を振り回す前に、散布図(Scatter plot)を書きます。

散布図とは、変数２つを、それぞれ横軸と縦軸にとった図を言います。まずは見てみましょう。

このような、

 - 1番めのご家庭は、お父さんの身長が165.22cmで、お子さんは151.83cm、
 - 2番めのご家庭は、お父さんの身長が160.65cmで、お子さんは160.56cm

というようなデータがあるとします。

```{r include=FALSE}
#install.package("UsingR")
library(UsingR)
data(father.son)
fs <- father.son * 2.54 # inch to cm
colnames(fs) <- c("Father", "Son")
```

```{r echo=FALSE}
head(fs)
```


このような、$(父親/Father, 息子/Son)$のデータの組を、散布図で表現すると、次のようになります。

```{r  echo=FALSE, fig.asp = 1}
plot(Son ~ Father, data=fs,bty="l",pch=20, xlim=c(140,190), ylim=c(140,190))
```

目的変数(target variable)である$y$を縦軸、
説明変数(predicting variable)である$x$を横軸に取ります。
ですから、これは、父親の身長(説明変数)によって、息子の身長(目的変数)が変わるだろうか？を知りたい時の散布図です。

ひとつひとつの点の場所を見ると、先程の$(父親, 息子)$のデータが、完全に表現されていることがわかります。

この図では、今回、1000ものご家庭が調査に協力してくれましたが、
**「たった一本の直線で、これら1,000のご家庭データから分かる、【父の身長と子の身長の関係】を表現しよう！」というのが、単回帰のコンセプトです。**

先に、線を引いてしまいましょう

```{r echo=FALSE, fig.asp = 1}
plot(Son ~ Father, data=fs,bty="l",pch=20, xlim=c(140,190), ylim=c(140,190))

result <- lm(Son ~ Father, data = fs)
abline(result, col="red")

#summary(result)  
```

**これです！この赤い線を引くことが「単回帰分析」です。**
確かにこの赤い線は、この父と子の背の高さの、
ちょうど真ん中あたりを、うまく通っていそうな感じがします。

この**適切な赤い線－これを「回帰直線」というのですが－**をもって、統計学者たちは「父と子の、身長の**関係がモデル化できた**」といい、
「父親の身長を教えてくれれば、ある年齢の息子の身長を、高い精度で予測してみせる」と言うわけです。



**全く同じグラフ**を、少しカメラを引いて描写してみると、
こんなふうになります。
```{r echo=FALSE, fig.asp=1}

plot(Son ~ Father, data=fs,bty="l",pch=20,xlim=c(0,190), ylim=c(0,190))
abline(result, col="red")
```





では、そのような直線は、どうやって引けばいいのでしょうか？
そもそも、「よい直線」と「ダメな直線」は、どう見分けたらいいのでしょうか？


例えば、たまたま父親と同じ身長の人が居たとして、
その人が、

「オレ、パパと同じ身長なんだ。だから、みんなは、パパと同じくらい身長があるのが普通だと思うよ」

と言ったとましょう。


彼の主張を、グラフに青線で書き入れると、こうなります。

```{r echo=FALSE, fig.asp=1}
plot(Son ~ Father, data=fs,bty="l",pch=20,xlim=c(140,190), ylim=c(140,190))
abline(result, col="red")
abline(0,1, col="blue") 
```

この青い線は、父親が150cmの時、息子も150cm、父親が160cmの時、息子も160cm…。という点をつないでできた線です。
数学的に書くなら、$y = x$の直線です。

たしかに、彼の主張も、そんなに的を外してはなさそうです。
では、どう考えればよいのでしょうか？どちらが、正しいのでしょうか？


\[
y_i = \beta_0 + \beta_1 x_{i} + \epsilon_i
\]



##回帰分析とは



##線形回帰




#線形回帰分析 - Linear Regression 2.重回帰
回帰分析について学んでいきましょう！！



#統計デモ


#参考文献

 - STAT-GB/2301 by Jeffrey S. Simonoff in New York University
 

